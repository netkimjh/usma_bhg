<!DOCTYPE html>
<html>
<head>
<script src="http://static.robotwebtools.org/EventEmitter2/current/eventemitter2.min.js"></script>
<script src="http://static.robotwebtools.org/roslibjs/current/roslib.min.js"></script>
<script src="http://cdnjs.cloudflare.com/ajax/libs/three.js/r71/three.min.js"></script>
<script>

      var alpha, valpha, z;
      var beta, vbeta, x;
      var gamma, vgamma, y;
      var cameraTimer;

// setup event handler to capture the orientation event and store the most recent data in a variable

      if (window.DeviceOrientationEvent) {
        // Listen for the deviceorientation event and handle the raw data
        window.addEventListener('deviceorientation', function(eventData) {
          // gamma is the left-to-right tilt in degrees, where right is positive
          gamma = eventData.gamma;
          
          // beta is the front-to-back tilt in degrees, where front is positive
          beta = eventData.beta;
          
          // alpha is the compass direction the device is facing in degrees
          alpha = eventData.alpha

          }, false);
        };

// setup event handler to capture the acceleration event and store the most recent data in a variable

        if (window.DeviceMotionEvent) {
          window.addEventListener('devicemotion', deviceMotionHandler, false);
        } else {
          window.alert("acceleration measurements Not supported.");
        }

        function deviceMotionHandler(eventData) {
          // Grab the acceleration from the results
          var acceleration = eventData.acceleration;
          x = acceleration.x;
          y = acceleration.y;
          z = acceleration.z;

          // Grab the rotation rate from the results
          var rotation = eventData.rotationRate;
          vgamma = rotation.gamma;  
          vbeta = rotation.beta;
          valpha = rotation.alpha;
}


// setup connection to the ROS server and prepare the topic
  var ros = new ROSLIB.Ros();

  ros.on('connection', function() { console.log('Connected to websocket server.');});

  ros.on('error', function(error) { console.log('Error connecting to websocket server: ', error); window.alert('Error connecting to websocket server'); });

  ros.on('close', function() { console.log('Connection to websocket server closed.');});

  var imageTopic = new ROSLIB.Topic({
    ros : ros,
    name : '/camera/image_color',
    messageType : 'sensor_msgs/Image'
  });
</script>
</head>

<!-- declare interface and the canvases that will display the video and the still shots -->
<body>
 <video style="display: none" autoplay id="video"></video>
 <canvas style="display: none" id="canvas"></canvas>
 <button id="startstop" style="outline-width: 0; background-color: transparent; border: none"><img id="startstopicon" src=""/></button>

<script>

      document.getElementById('startstopicon').setAttribute('src', RECORD_OFF);

// request access to the video camera and start the video stream
  var hasRunOnce = false,
      video        = document.querySelector('#video'),
      canvas       = document.querySelector('#canvas'),
      width = 640,
      height,           // calculated once video stream size is known
      cameraStream;


  function cameraOn() {
          navigator.getMedia = ( navigator.getUserMedia ||
                                 navigator.webkitGetUserMedia ||
                                 navigator.mozGetUserMedia ||
                                 navigator.msGetUserMedia);

          navigator.getMedia(
            {
              video: true,
              audio: false
            },
            function(stream) {
              cameraStream = stream;
              if (navigator.mozGetUserMedia) {
                video.mozSrcObject = stream;
              } else {
                var vendorURL = window.URL || window.webkitURL;
                video.src = vendorURL.createObjectURL(stream);
              }
              video.play();
            },
            function(err) {
              console.log("An error occured! " + err);
              window.alert("An error occured! " + err);
            }
          );
  }


  function cameraOff() {
        cameraStream.stop();
        hasRunOnce = false;
        takepicture();                  // blank the screen to prevent last image from staying
    }

// function that is run once scale the height of the video stream to match the configured target width
  video.addEventListener('canplay', function(ev){
    if (!hasRunOnce) {
      height = video.videoHeight / (video.videoWidth/width);
      video.setAttribute('width', width);
      video.setAttribute('height', height);
      canvas.setAttribute('width', width);
      canvas.setAttribute('height', height);
      hasRunOnce = true;
    }
  }, false);

// function that is run by trigger several times a second
// takes snapshot of video to canvas, encodes the images as base 64 and sends it to the ROS topic
  function takepicture() {
    canvas.width = width;
    canvas.height = height;

    canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);   
 
    var data = canvas.toDataURL('image/jpeg');
    var imageMessage = new ROSLIB.Message({
        format : "jpeg",
        data : data.replace("data:image/jpeg;base64,", "")
    });

    imageTopic.publish(imageMessage);
  }

// turning on and off the timer that triggers sending pictures several times a second
  startstopicon.addEventListener('click', function(ev){
      if(cameraTimer == null) {
          ros.connect("ws://localhost:9090");
          cameraOn();
          cameraTimer = setInterval(function(){
                takepicture();
           }, 250);       // publish an image 4 times per second
       } else {
           ros.close();
           cameraOff();
           clearInterval(cameraTimer);
           cameraTimer = null;
       }
  }, false);
</script>
</body>
</html>
